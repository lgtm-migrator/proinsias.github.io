<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.4">Jekyll</generator><link href="https://proinsias.github.io/pages/proinsias/feed.xml" rel="self" type="application/atom+xml" /><link href="https://proinsias.github.io/pages/proinsias/" rel="alternate" type="text/html" /><updated>2018-10-12T15:11:12+00:00</updated><id>https://proinsias.github.io/pages/proinsias/</id><title type="html">An independent mind…</title><subtitle>My home on the web.</subtitle><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><entry><title type="html">Are categorical variables getting lost in your random forests?</title><link href="https://proinsias.github.io/pages/proinsias/Are-categorical-variables-getting-lost-in-your-random-forests/" rel="alternate" type="text/html" title="Are categorical variables getting lost in your random forests?" /><published>2018-07-12T15:35:00+00:00</published><updated>2018-07-12T15:35:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Are-categorical-variables-getting-lost-in-your-random-forests</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Are-categorical-variables-getting-lost-in-your-random-forests/">&lt;p&gt;I’ve been one-hot encoding categorical variables for as long as I have been using
sci-kit learn.
It turns out that you can lose a lot of predictive power this way,
and that alternatives do exist.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Decision tree models can handle categorical variables without one-hot encoding them.
  However, popular implementations of decision trees (and random forests) differ
  as to whether they honor this fact.
  We show that one-hot encoding can seriously degrade tree-model performance.
  Our primary comparison is between H2O (which honors categorical variables)
  and scikit-learn (which requires them to be one-hot encoded).&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(via &lt;a href=&quot;https://roamanalytics.com/2016/10/28/are-categorical-variables-getting-lost-in-your-random-forests/&quot;&gt;Are categorical variables getting lost in your random forests?&lt;/a&gt;
)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">I’ve been one-hot encoding categorical variables for as long as I have been using sci-kit learn. It turns out that you can lose a lot of predictive power this way, and that alternatives do exist.</summary></entry><entry><title type="html">Using multiple worktrees with git</title><link href="https://proinsias.github.io/pages/proinsias/Using-multiple-worktrees-with-git/" rel="alternate" type="text/html" title="Using multiple worktrees with git" /><published>2017-07-12T12:06:00+00:00</published><updated>2017-07-12T12:06:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Using-multiple-worktrees-with-git</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Using-multiple-worktrees-with-git/">&lt;blockquote&gt;
  &lt;p&gt;When working with multiple branches at the same time, people clone the whole
git repository again.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;I am one of these people. I have been using &lt;code class=&quot;highlighter-rouge&quot;&gt;git&lt;/code&gt; for years, and I can’t believe
I’ve not known about &lt;code class=&quot;highlighter-rouge&quot;&gt;git worktree&lt;/code&gt;! – this makes it easy to work on various
braches in the same repository without having to clone a new copy of the repo.&lt;/p&gt;

&lt;p&gt;(via &lt;a href=&quot;https://stacktoheap.com/blog/2016/01/19/using-multiple-worktrees-with-git/&quot;&gt;Using multiple worktrees with git&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">When working with multiple branches at the same time, people clone the whole git repository again.</summary></entry><entry><title type="html">Gathering weak npm credentials</title><link href="https://proinsias.github.io/pages/proinsias/Gathering-weak-npm-credentials/" rel="alternate" type="text/html" title="Gathering weak npm credentials" /><published>2017-07-06T10:41:00+00:00</published><updated>2017-07-06T10:41:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Gathering-weak-npm-credentials</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Gathering-weak-npm-credentials/">&lt;p&gt;We &lt;em&gt;all&lt;/em&gt; know the importance of strong passwords, don’t we?&lt;/p&gt;

&lt;p&gt;In case you don’t, here’s an
&lt;a href=&quot;https://github.com/ChALkeR/notes/blob/master/Gathering-weak-npm-credentials.md&quot;&gt;example&lt;/a&gt;
of how a security researcher was able to
obtain direct publish access to &lt;em&gt;14%&lt;/em&gt; of npm packages through some fairly
basic techniques that take advantage of poor password practices.&lt;/p&gt;

&lt;p&gt;(via &lt;a href=&quot;https://github.com/ChALkeR/&quot;&gt;ChALkeR&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">We all know the importance of strong passwords, don’t we?</summary></entry><entry><title type="html">Canonical Correlation Analysis for Analyzing Sequences of Medical Billing Codes</title><link href="https://proinsias.github.io/pages/proinsias/CCA-for-Analyzing-Sequences-of-Medical-Billing-Codes/" rel="alternate" type="text/html" title="Canonical Correlation Analysis for Analyzing Sequences of Medical Billing Codes" /><published>2017-05-25T15:51:00+00:00</published><updated>2017-05-25T15:51:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/CCA-for-Analyzing-Sequences-of-Medical-Billing-Codes</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/CCA-for-Analyzing-Sequences-of-Medical-Billing-Codes/">&lt;p&gt;Due to the vast number of medical billing codes, it is generally infeasible to
generate machine learning features from them as one-hot vectors.
&lt;a href=&quot;https://arxiv.org/abs/1612.00516&quot;&gt;This paper&lt;/a&gt; discusses the use of
&lt;a href=&quot;https://en.wikipedia.org/wiki/Canonical_correlation&quot;&gt;Canonical Correlation Analysis&lt;/a&gt;
to reduce this dimensionality and capture the inherent relationships that exist
between the codes.&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">Due to the vast number of medical billing codes, it is generally infeasible to generate machine learning features from them as one-hot vectors. This paper discusses the use of Canonical Correlation Analysis to reduce this dimensionality and capture the inherent relationships that exist between the codes.</summary></entry><entry><title type="html">Explaining complex machine learning models with LIME</title><link href="https://proinsias.github.io/pages/proinsias/Explaining-complex-machine-learning-models-with-LIME/" rel="alternate" type="text/html" title="Explaining complex machine learning models with LIME" /><published>2017-05-01T10:48:00+00:00</published><updated>2017-05-01T10:48:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Explaining-complex-machine-learning-models-with-LIME</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Explaining-complex-machine-learning-models-with-LIME/">&lt;p&gt;Another nice
&lt;a href=&quot;https://shiring.github.io/machine_learning/2017/04/23/lime&quot;&gt;write-up&lt;/a&gt;
on the use of Local Interpretable Model-Agnostic Explanations (LIME) to
explain complex machine learning models.&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">Another nice write-up on the use of Local Interpretable Model-Agnostic Explanations (LIME) to explain complex machine learning models.</summary></entry><entry><title type="html">Combating Fake News With a Smartphone</title><link href="https://proinsias.github.io/pages/proinsias/Combating-Fake-News-With-a-Smartphone/" rel="alternate" type="text/html" title="Combating Fake News With a Smartphone" /><published>2017-03-09T10:01:00+00:00</published><updated>2017-03-09T10:01:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Combating-Fake-News-With-a-Smartphone</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Combating-Fake-News-With-a-Smartphone/">&lt;blockquote&gt;
  &lt;p&gt;Automatically [add] extra digital proof data to all photos and videos you take.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Pretty cool!&lt;/p&gt;

&lt;p&gt;(via the &lt;a href=&quot;https://guardianproject.info/2017/02/24/combating-fake-news-with-a-smartphone-proof-mode/&quot;&gt;Guardian Project&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">Automatically [add] extra digital proof data to all photos and videos you take.</summary></entry><entry><title type="html">SHAttered</title><link href="https://proinsias.github.io/pages/proinsias/SHAttered/" rel="alternate" type="text/html" title="SHAttered" /><published>2017-02-23T10:43:00+00:00</published><updated>2017-02-23T10:43:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/SHAttered</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/SHAttered/">&lt;p&gt;Awesome work to demonstrate how to deliberately cause a SHA-1 collision.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;It is now practically possible to craft two colliding PDF files and obtain a
SHA-1 digital signature on the first PDF file which can also be abused as a 
valid signature on the second PDF file.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(via &lt;a href=&quot;https://shattered.it/&quot;&gt;SHAttered&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">Awesome work to demonstrate how to deliberately cause a SHA-1 collision.</summary></entry><entry><title type="html">Unlearning descriptive statistics</title><link href="https://proinsias.github.io/pages/proinsias/Unlearning-descriptive-statistics/" rel="alternate" type="text/html" title="Unlearning descriptive statistics" /><published>2017-02-10T16:54:00+00:00</published><updated>2017-02-10T16:54:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/Unlearning-descriptive-statistics</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/Unlearning-descriptive-statistics/">&lt;p&gt;Top tips on better descriptive statistics:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Instead of the mean, use the median and/or the mode.&lt;/li&gt;
  &lt;li&gt;Instead of the standard deviation, use the mean absolute deviation, the median absolute deviation, or the interquartile range.&lt;/li&gt;
  &lt;li&gt;Instead of z-scores, use percentile ranks.&lt;/li&gt;
  &lt;li&gt;Instead of skewness, use a QQ-plot or a histogram.&lt;/li&gt;
  &lt;li&gt;Instead of x standard deviations from the mean, use x median absolute deviations from the median.&lt;/li&gt;
  &lt;li&gt;Instead of correlation metrics, just use a scatterplot.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(via &lt;a href=&quot;http://debrouwere.org/2017/02/01/unlearning-descriptive-statistics/&quot;&gt;Unlearning descriptive statistics&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">Top tips on better descriptive statistics:</summary></entry><entry><title type="html">The legends of mathematics that almost never were</title><link href="https://proinsias.github.io/pages/proinsias/The-legends-of-mathematics-that-almost-never-were/" rel="alternate" type="text/html" title="The legends of mathematics that almost never were" /><published>2017-02-07T14:06:00+00:00</published><updated>2017-02-07T14:06:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/The-legends-of-mathematics-that-almost-never-were</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/The-legends-of-mathematics-that-almost-never-were/">&lt;p&gt;It’s always made me sad when people tell me they dislike mathematics.
I always wonder if it was the subject or their teachers that they disliked…&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Mathematical genius resides within every one of us. Most people just don’t know it yet. That’s because genius is fragile. If you don’t embraced genius and tend to with care, it will slip away, leaving behind just a subdued vision of the mathematicians we could have become.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(via &lt;a href=&quot;https://medium.freecodecamp.com/mathematical-genius-is-fragile-society-needs-to-stop-destroying-it-5fdf3f08336e#.o72a1bds9&quot;&gt;Mathematical genius is fragile. We need to stop destroying it.&lt;/a&gt;)&lt;/p&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">It’s always made me sad when people tell me they dislike mathematics. I always wonder if it was the subject or their teachers that they disliked…</summary></entry><entry><title type="html">The Truth About Bad Science</title><link href="https://proinsias.github.io/pages/proinsias/The-Truth-About-Bad-Science/" rel="alternate" type="text/html" title="The Truth About Bad Science" /><published>2017-01-26T10:20:00+00:00</published><updated>2017-01-26T10:20:00+00:00</updated><id>https://proinsias.github.io/pages/proinsias/The-Truth-About-Bad-Science</id><content type="html" xml:base="https://proinsias.github.io/pages/proinsias/The-Truth-About-Bad-Science/">&lt;p&gt;&lt;a href=&quot;http://bit.ly/2kwWpYO&quot;&gt;This wired.com article&lt;/a&gt;
on ‘bad science’ speaks to me on so many levels.
It hurts my soul to see how many published studies are not reproducible.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“A new study shows…” are “the four most dangerous words”.&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Francis T. O'Donovan</name><email>francis.odonovan@gmail.com</email><uri>https://proinsias.github.io/</uri></author><summary type="html">This wired.com article on ‘bad science’ speaks to me on so many levels. It hurts my soul to see how many published studies are not reproducible.</summary></entry></feed>